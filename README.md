# ğŸ‘½ RAG PDFBot

A sophisticated Retrieval-Augmented Generation (RAG) system that enables users to chat with multiple PDF documents using Large Language Models (LLMs). Built with FastAPI backend, Streamlit frontend, and Docker containerization.

## ğŸŒŸ Features

- **Multi-PDF Support**: Upload and process multiple PDF documents simultaneously
- **RAG Architecture**: Combines document retrieval with LLM generation for accurate responses
- **Multiple LLM Providers**: Currently supports Groq (compound-beta, compound-beta-mini)
- **Vector Database**: Uses ChromaDB for efficient document similarity search
- **Interactive Chat Interface**: Real-time conversation with your documents
- **Document Inspector**: Examine retrieved chunks and vector store statistics
- **Chat History**: Download conversation history as CSV
- **Containerized Deployment**: Easy deployment with Docker Compose
- **Comprehensive Testing**: Unit tests for both client and server components

## ğŸ—ï¸ Architecture

### System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     â”‚    â”‚                     â”‚    â”‚                     â”‚
â”‚   Streamlit Client  â”‚â—„â”€â”€â–ºâ”‚   FastAPI Server    â”‚â—„â”€â”€â–ºâ”‚   External Services â”‚
â”‚                     â”‚    â”‚                     â”‚    â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                           â”‚                           â”‚
          â”‚                           â”‚                           â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚  UI Layer â”‚              â”‚ API Layer â”‚              â”‚    Groq   â”‚
    â”‚           â”‚              â”‚           â”‚              â”‚    API    â”‚
    â”‚ - Chat    â”‚              â”‚ - Routes  â”‚              â”‚           â”‚
    â”‚ - Upload  â”‚              â”‚ - Schemas â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚ - Config  â”‚              â”‚ - Models  â”‚
    â”‚ - History â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
                                      â”‚
                              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                              â”‚Core Layer â”‚
                              â”‚           â”‚
                              â”‚ - LLM     â”‚
                              â”‚ - Vector  â”‚
                              â”‚ - Process â”‚
                              â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                                    â”‚
                              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
                              â”‚Data Layer â”‚
                              â”‚           â”‚
                              â”‚ - ChromaDBâ”‚
                              â”‚ - Files   â”‚
                              â”‚ - Embeddingsâ”‚
                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Architecture

#### 1. Client (Streamlit Frontend)

```
client/
â”œâ”€â”€ app.py                 # Main application entry point
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ chat.py           # Chat interface and history
â”‚   â”œâ”€â”€ sidebar.py        # Configuration and controls
â”‚   â””â”€â”€ inspector.py      # Vector store inspection tools
â”œâ”€â”€ state/
â”‚   â””â”€â”€ session.py        # Session state management
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ api.py           # API communication layer
â”‚   â”œâ”€â”€ config.py        # Configuration settings
â”‚   â””â”€â”€ helpers.py       # Helper functions
â””â”€â”€ tests/               # Unit tests
```

**Key Components:**

- **App.py**: Main orchestrator that manages the overall application flow
- **Chat Component**: Handles user input, message display, and chat history
- **Sidebar Component**: Model selection, file upload, and utility functions
- **Inspector Component**: Vector store debugging and chunk inspection
- **Session State**: Manages application state across interactions
- **API Layer**: Handles communication with FastAPI backend

#### 2. Server (FastAPI Backend)

```
server/
â”œâ”€â”€ main.py              # FastAPI application entry point
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ routes.py        # API endpoints
â”‚   â””â”€â”€ schemas.py       # Pydantic models
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ llm_chain_factory.py    # LLM chain creation
â”‚   â”œâ”€â”€ vector_database.py      # Vector store operations
â”‚   â””â”€â”€ document_processor.py   # PDF processing
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py      # Application configuration
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ logger.py        # Logging configuration
â””â”€â”€ tests/               # Unit tests
```

**Key Components:**

- **Routes**: RESTful API endpoints for all operations
- **LLM Chain Factory**: Creates and configures LangChain pipelines
- **Vector Database**: Manages ChromaDB operations and embeddings
- **Document Processor**: Handles PDF parsing and text chunking
- **Configuration**: Centralized settings and environment variables

### Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User      â”‚    â”‚  Streamlit  â”‚    â”‚   FastAPI   â”‚    â”‚   ChromaDB  â”‚
â”‚   Action    â”‚    â”‚   Client    â”‚    â”‚   Server    â”‚    â”‚   Vector    â”‚
â”‚             â”‚    â”‚             â”‚    â”‚             â”‚    â”‚   Store     â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                  â”‚                  â”‚                  â”‚
      â”‚ 1. Upload PDFs   â”‚                  â”‚                  â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                  â”‚                  â”‚
      â”‚                  â”‚ 2. POST /upload  â”‚                  â”‚
      â”‚                  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                  â”‚
      â”‚                  â”‚                  â”‚ 3. Process & Storeâ”‚
      â”‚                  â”‚                  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
      â”‚                  â”‚                  â”‚                  â”‚
      â”‚                  â”‚ 4. Success       â”‚                  â”‚
      â”‚                  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚
      â”‚ 5. Ask Question  â”‚                  â”‚                  â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                  â”‚                  â”‚
      â”‚                  â”‚ 6. POST /chat    â”‚                  â”‚
      â”‚                  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚                  â”‚
      â”‚                  â”‚                  â”‚ 7. Query Vector  â”‚
      â”‚                  â”‚                  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚
      â”‚                  â”‚                  â”‚                  â”‚
      â”‚                  â”‚                  â”‚ 8. Similar Chunksâ”‚
      â”‚                  â”‚                  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
      â”‚                  â”‚                  â”‚                  â”‚
      â”‚                  â”‚                  â”‚ 9. LLM Processingâ”‚
      â”‚                  â”‚                  â”‚ (Groq API)       â”‚
      â”‚                  â”‚                  â”‚                  â”‚
      â”‚                  â”‚ 10. AI Response  â”‚                  â”‚
      â”‚                  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚
      â”‚ 11. Display      â”‚                  â”‚                  â”‚
      â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                  â”‚                  â”‚
```

### Technical Stack

#### Frontend (Streamlit)
- **Framework**: Streamlit 1.x
- **HTTP Client**: Requests
- **Data Processing**: Pandas
- **State Management**: Streamlit Session State
- **UI Components**: Native Streamlit widgets

#### Backend (FastAPI)
- **Framework**: FastAPI
- **LLM Framework**: LangChain
- **Vector Database**: ChromaDB
- **Embeddings**: HuggingFace Transformers (all-MiniLM-L12-v2)
- **PDF Processing**: PyPDF
- **Text Splitting**: TokenTextSplitter
- **LLM Provider**: Groq
- **Async Support**: Python asyncio

#### Infrastructure
- **Containerization**: Docker & Docker Compose
- **File Storage**: Local filesystem with Docker volumes
- **Environment Management**: python-dotenv
- **Logging**: Python logging module
- **Testing**: pytest, pytest-mock

## ğŸš€ Quick Start

### Prerequisites

- Docker and Docker Compose
- Groq API key (get it from [Groq Console](https://console.groq.com))

### Installation

1. **Clone the repository**
   ```bash
   git clone [<repository-url>](https://github.com/furkan-cyber/project.git)
   cd rag-pdfbot
   ```

2. **Set up environment variables**
   ```bash
   cp .env.example .env
   # Edit .env and add your GROQ_API_KEY
   ```

3. **Start the application**
   ```bash
   docker-compose up -d
   ```

4. **Access the application**
   - Frontend: http://localhost:8501
   - Backend API: http://localhost:8000
   - API Documentation: http://localhost:8000/docs

### Manual Setup (Development)

#### Server Setup
```bash
cd server
pip install -r requirements.txt
python main.py
```

#### Client Setup
```bash
cd client
pip install -r requirements.txt
streamlit run app.py
```

## ğŸ“– Usage Guide

### 1. Configure Model
- Select a model provider (Groq)
- Choose a specific model (compound-beta, compound-beta-mini)

### 2. Upload PDFs
- Click "Upload PDFs" in the sidebar
- Select one or multiple PDF files
- Click "Submit" to process the documents

### 3. Chat with Documents
- Type your questions in the chat input
- Receive AI-generated responses based on your documents
- View conversation history

### 4. Inspect Vector Store
- Switch to "Inspector" view
- Test queries against the vector database
- View matching document chunks
- Check document count in the vector store

### 5. Manage Sessions
- Download chat history as CSV
- Clear chat history
- Reset entire session
- Undo last message

## ğŸ”§ API Reference

### Authentication
Currently, no authentication is required. The API runs on `http://localhost:8000`.

### Endpoints

#### Health Check
```http
GET /health
```
Returns service health status.

#### Get LLM Providers
```http
GET /llm
```
Returns available LLM providers.

#### Get Models for Provider
```http
GET /llm/{model_provider}
```
Returns available models for a specific provider.

#### Upload and Process PDFs
```http
POST /upload_and_process_pdfs
Content-Type: multipart/form-data

files: [PDF files]
model_provider: string
```

#### Chat
```http
POST /chat
Content-Type: application/json

{
  "model_provider": "groq",
  "model_name": "compound-beta",
  "message": "Your question here"
}
```

#### Vector Store Search
```http
POST /vector_store/search
Content-Type: application/json

{
  "model_provider": "groq",
  "query": "search query"
}
```

#### Get Vector Store Count
```http
GET /vector_store/count/{model_provider}
```

### Response Format
All API responses follow this structure:
```json
{
  "status": "success|error",
  "data": "response data",
  "message": "optional message"
}
```

## ğŸ§ª Testing

### Running Tests

#### Server Tests
```bash
cd server
pip install -r requirements-test.txt
pytest tests/ -v
```

#### Client Tests
```bash
cd client
pip install -r requirements-test.txt
pytest tests/ -v
```

### Test Coverage
- **Routes**: API endpoint functionality
- **Vector Database**: CRUD operations and search
- **Document Processing**: PDF parsing and chunking
- **Session Management**: State handling
- **Helper Functions**: Utility function behavior

## ğŸ“ Project Structure

```
project/
â”œâ”€â”€ client/                 # Streamlit frontend
â”‚   â”œâ”€â”€ app.py             # Main application
â”‚   â”œâ”€â”€ components/        # UI components
â”‚   â”œâ”€â”€ state/            # Session management
â”‚   â”œâ”€â”€ utils/            # Utilities and API calls
â”‚   â”œâ”€â”€ tests/            # Unit tests
â”‚   â”œâ”€â”€ Dockerfile        # Client container
â”‚   â””â”€â”€ requirements.txt  # Python dependencies
â”œâ”€â”€ server/                # FastAPI backend
â”‚   â”œâ”€â”€ main.py           # Server entry point
â”‚   â”œâ”€â”€ api/              # API routes and schemas
â”‚   â”œâ”€â”€ core/             # Core business logic
â”‚   â”œâ”€â”€ config/           # Configuration
â”‚   â”œâ”€â”€ utils/            # Utilities
â”‚   â”œâ”€â”€ tests/            # Unit tests
â”‚   â”œâ”€â”€ Dockerfile        # Server container
â”‚   â””â”€â”€ requirements.txt  # Python dependencies
â”œâ”€â”€ .env                  # Environment variables
â”œâ”€â”€ docker-compose.yml    # Container orchestration
â””â”€â”€ README.md            # This file
```

## ğŸ”§ Configuration

### Environment Variables

```bash
# Required
GROQ_API_KEY=your_groq_api_key_here

# Optional
API_URL=http://localhost:8000  # Backend URL for client
```

### Model Configuration

Edit `server/config/settings.py` to add new models or providers:

```python
MODEL_OPTIONS = {
  "groq": {
    "playground": "https://console.groq.com",
    "models": ["compound-beta", "compound-beta-mini"]
  },
  # Add new providers here
}
```

### Vector Store Settings

- **Embedding Model**: sentence-transformers/all-MiniLM-L12-v2
- **Chunk Size**: 500 tokens
- **Chunk Overlap**: 50 tokens
- **Search Results**: Top 3 similar chunks
- **Storage**: Local filesystem with Docker volumes

## ğŸ” Troubleshooting

### Common Issues

1. **API Key Error**
   - Ensure GROQ_API_KEY is set in .env file
   - Verify API key is valid and active

2. **File Upload Fails**
   - Check file size (max 200MB per file)
   - Ensure files are valid PDF format
   - Verify server has write permissions

3. **Chat Not Working**
   - Ensure PDFs are uploaded and processed
   - Check if model provider is selected
   - Verify backend server is running

4. **Vector Store Issues**
   - Clear vector store: `docker-compose down -v`
   - Restart services: `docker-compose up -d`

### Logs

View application logs:
```bash
# Server logs
docker-compose logs server

# Client logs
docker-compose logs client

# All logs
docker-compose logs -f
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Run the test suite
6. Submit a pull request

### Development Setup

```bash
# Install development dependencies
pip install -r requirements-test.txt

# Run tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=. --cov-report=html
```

## ğŸ“„ License

This project is licensed under the MIT License. See the LICENSE file for details.

## ğŸ™ Acknowledgments

- [LangChain](https://langchain.com/) for the RAG framework
- [Streamlit](https://streamlit.io/) for the frontend framework
- [FastAPI](https://fastapi.tiangolo.com/) for the backend framework
- [ChromaDB](https://www.trychroma.com/) for vector storage
- [Groq](https://groq.com/) for LLM inference
- [HuggingFace](https://huggingface.co/) for embeddings

## ğŸ“ Support

For support, questions, or feature requests:
- Create an issue in the GitHub repository
- Check the troubleshooting section above
- Review the API documentation at `/docs`

---

Built with â¤ï¸ for the AI community
